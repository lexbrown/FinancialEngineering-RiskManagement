{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка показателей Открытых Данных\n",
    "\n",
    "Обновленные проверки от 30.05.2018\n",
    "\n",
    "Показатели:\n",
    "* 001 - Количество заявок на потребительские кредиты **с 2013**\n",
    "* 002 - Средняя сумма заявки на потребительский кредит **с 2013**\n",
    "* 003 - Количество заявок на ипотечные кредиты **с 2013**\n",
    "* 004 - Средняя сумма заявки на ипотечный кредит **с 2013**\n",
    "* 007 - Количество новых депозитов **с 2014**\n",
    "* 008 - Средняя сумма новго депозита **с 2014**\n",
    "* 009 - Средние расходы по картам **с 2014**\n",
    "* 011 - Средний чек в формате фастфуд\n",
    "* 012 - Средний чек в формате ресторан\n",
    "* 014 - Средние траты в формате фастфуд\n",
    "* 015 - Средние траты в формате ресторан\n",
    "* 020 - Средняя зарплата **с 2015**\n",
    "* 021 - Средняя пенсия **с 2014**\n",
    "* 038 - Рублей в среднем на текущем счете человека **с 2014**\n",
    "* 039 - В среднем депозитов в рублях на человека **с 2014**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{width:95% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import MonthEnd \n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import warnings\n",
    "import datetime as dt\n",
    "\n",
    "from transliterate import translit\n",
    "from __future__ import division\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container{width:95% !important;}</style>\"))\n",
    "\n",
    "pd.set_option('display.max_rows',100)\n",
    "pd.set_option('display.max_columns',160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dateparse = lambda x: pd.datetime.strptime(x, '%d.%m.%Y')\n",
    "dateparse2 = lambda x: pd.datetime.strptime(x, '%m-%d-%Y')\n",
    "dateparse3 = lambda x: pd.datetime.strptime(x, '%m.%d.%Y')\n",
    "dateparse4 = lambda x: pd.datetime.strptime(x, '%d-%m-%Y')\n",
    "\n",
    "def load_dataset(name_of_file):\n",
    "    '''\n",
    "    Метод загружает данные из csv в pandas dataframe\n",
    "    '''\n",
    "    # 2 вида записи дат существует в файлах, пробуем первый или второй\n",
    "    try:\n",
    "        df = pd.read_csv(name_of_file, encoding='utf-8', sep='|', header=0, dtype={'main_ind': np.float64}, decimal=',', parse_dates=['ReportDate'], date_parser=dateparse2)\n",
    "    except:\n",
    "        df = pd.read_csv(name_of_file, encoding='utf-8', sep='|', header=0, dtype={'main_ind': np.float64}, decimal=',', parse_dates=['ReportDate'], date_parser=dateparse2)\n",
    "    #else:\n",
    "    #    df = pd.read_csv(name_of_file, encoding='utf-8', sep='|', header=0, dtype={'main_ind': np.float64}, decimal=',', parse_dates=['ReportDate'], date_parser=dateparse)   \n",
    "    df = df.rename(columns={df.columns[0]:'ReportDate',df.columns[1]:'subj'})\n",
    "    df.ReportDate = pd.to_datetime(df.ReportDate)\n",
    "    #Записываем названия регионов транслитом\n",
    "    df.subj = df.subj.map(lambda x: translit(x, reversed=True) if x != 'UNKNOWN'  else x)  \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReportDate</th>\n",
       "      <th>subj</th>\n",
       "      <th>cnt_client_tid</th>\n",
       "      <th>sum_trans_cnt</th>\n",
       "      <th>main_ind</th>\n",
       "      <th>main_ind_sum</th>\n",
       "      <th>main_ind_median</th>\n",
       "      <th>main_ind_avg</th>\n",
       "      <th>main_ind_procentile_10</th>\n",
       "      <th>main_ind_procentile_90</th>\n",
       "      <th>main_ind_max</th>\n",
       "      <th>main_ind_min</th>\n",
       "      <th>main_ind_sd</th>\n",
       "      <th>main_ind_descr</th>\n",
       "      <th>secondary1_ind_sum</th>\n",
       "      <th>secondary1_ind_median</th>\n",
       "      <th>secondary1_ind_avg</th>\n",
       "      <th>secondary1_ind_procentile_10</th>\n",
       "      <th>secondary1_ind_procentile_90</th>\n",
       "      <th>secondary1_ind_max</th>\n",
       "      <th>secondary1_ind_min</th>\n",
       "      <th>secondary1_ind_descr</th>\n",
       "      <th>secondary1_ind_sd</th>\n",
       "      <th>secondary2_ind_sum</th>\n",
       "      <th>secondary2_ind_median</th>\n",
       "      <th>secondary2_ind_avg</th>\n",
       "      <th>secondary2_ind_procentile_10</th>\n",
       "      <th>secondary2_ind_procentile_90</th>\n",
       "      <th>secondary2_ind_max</th>\n",
       "      <th>secondary2_ind_min</th>\n",
       "      <th>secondary2_ind_sd</th>\n",
       "      <th>secondary2_ind_descr</th>\n",
       "      <th>population_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-15</td>\n",
       "      <td>Rossija</td>\n",
       "      <td>28995493</td>\n",
       "      <td>?</td>\n",
       "      <td>6936.2149</td>\n",
       "      <td>2.011190e+11</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>6936.2149</td>\n",
       "      <td>148.8</td>\n",
       "      <td>16108.060</td>\n",
       "      <td>2.174894e+07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>27384.8371</td>\n",
       "      <td>009 Средние расходы по картам.</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>06.07.2117 17:50:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-15</td>\n",
       "      <td>Rossija</td>\n",
       "      <td>29460943</td>\n",
       "      <td>?</td>\n",
       "      <td>6343.7634</td>\n",
       "      <td>1.868933e+11</td>\n",
       "      <td>1572.9</td>\n",
       "      <td>6343.7634</td>\n",
       "      <td>140.0</td>\n",
       "      <td>14766.380</td>\n",
       "      <td>1.951002e+07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>24783.0458</td>\n",
       "      <td>009 Средние расходы по картам.</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>06.07.2117 17:50:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-03-15</td>\n",
       "      <td>Rossija</td>\n",
       "      <td>31014964</td>\n",
       "      <td>?</td>\n",
       "      <td>7404.6714</td>\n",
       "      <td>2.296556e+11</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>7404.6714</td>\n",
       "      <td>150.0</td>\n",
       "      <td>17562.630</td>\n",
       "      <td>1.765036e+07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>27560.3622</td>\n",
       "      <td>009 Средние расходы по картам.</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>06.07.2117 17:50:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>Rossija</td>\n",
       "      <td>31361686</td>\n",
       "      <td>?</td>\n",
       "      <td>6969.3603</td>\n",
       "      <td>2.185709e+11</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>6969.3603</td>\n",
       "      <td>150.0</td>\n",
       "      <td>16364.000</td>\n",
       "      <td>2.199201e+07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>26518.3461</td>\n",
       "      <td>009 Средние расходы по картам.</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>06.07.2117 17:50:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-05-15</td>\n",
       "      <td>Rossija</td>\n",
       "      <td>31858357</td>\n",
       "      <td>?</td>\n",
       "      <td>7353.1625</td>\n",
       "      <td>2.342597e+11</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>7353.1625</td>\n",
       "      <td>150.0</td>\n",
       "      <td>17421.404</td>\n",
       "      <td>3.243784e+07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>27588.1739</td>\n",
       "      <td>009 Средние расходы по картам.</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>06.07.2117 17:50:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ReportDate     subj  cnt_client_tid sum_trans_cnt   main_ind  main_ind_sum  \\\n",
       "0 2014-01-15  Rossija        28995493             ?  6936.2149  2.011190e+11   \n",
       "1 2014-02-15  Rossija        29460943             ?  6343.7634  1.868933e+11   \n",
       "2 2014-03-15  Rossija        31014964             ?  7404.6714  2.296556e+11   \n",
       "3 2014-04-15  Rossija        31361686             ?  6969.3603  2.185709e+11   \n",
       "4 2014-05-15  Rossija        31858357             ?  7353.1625  2.342597e+11   \n",
       "\n",
       "   main_ind_median  main_ind_avg  main_ind_procentile_10  \\\n",
       "0           1600.0     6936.2149                   148.8   \n",
       "1           1572.9     6343.7634                   140.0   \n",
       "2           1884.0     7404.6714                   150.0   \n",
       "3           1769.0     6969.3603                   150.0   \n",
       "4           1901.0     7353.1625                   150.0   \n",
       "\n",
       "   main_ind_procentile_90  main_ind_max  main_ind_min  main_ind_sd  \\\n",
       "0               16108.060  2.174894e+07          0.01   27384.8371   \n",
       "1               14766.380  1.951002e+07          0.01   24783.0458   \n",
       "2               17562.630  1.765036e+07          0.01   27560.3622   \n",
       "3               16364.000  2.199201e+07          0.01   26518.3461   \n",
       "4               17421.404  3.243784e+07          0.01   27588.1739   \n",
       "\n",
       "                   main_ind_descr secondary1_ind_sum secondary1_ind_median  \\\n",
       "0  009 Средние расходы по картам.                  ?                     ?   \n",
       "1  009 Средние расходы по картам.                  ?                     ?   \n",
       "2  009 Средние расходы по картам.                  ?                     ?   \n",
       "3  009 Средние расходы по картам.                  ?                     ?   \n",
       "4  009 Средние расходы по картам.                  ?                     ?   \n",
       "\n",
       "  secondary1_ind_avg secondary1_ind_procentile_10  \\\n",
       "0                  ?                            ?   \n",
       "1                  ?                            ?   \n",
       "2                  ?                            ?   \n",
       "3                  ?                            ?   \n",
       "4                  ?                            ?   \n",
       "\n",
       "  secondary1_ind_procentile_90 secondary1_ind_max secondary1_ind_min  \\\n",
       "0                            ?                  ?                  ?   \n",
       "1                            ?                  ?                  ?   \n",
       "2                            ?                  ?                  ?   \n",
       "3                            ?                  ?                  ?   \n",
       "4                            ?                  ?                  ?   \n",
       "\n",
       "  secondary1_ind_descr secondary1_ind_sd secondary2_ind_sum  \\\n",
       "0                    ?                 ?                  ?   \n",
       "1                    ?                 ?                  ?   \n",
       "2                    ?                 ?                  ?   \n",
       "3                    ?                 ?                  ?   \n",
       "4                    ?                 ?                  ?   \n",
       "\n",
       "  secondary2_ind_median secondary2_ind_avg secondary2_ind_procentile_10  \\\n",
       "0                     ?                  ?                            ?   \n",
       "1                     ?                  ?                            ?   \n",
       "2                     ?                  ?                            ?   \n",
       "3                     ?                  ?                            ?   \n",
       "4                     ?                  ?                            ?   \n",
       "\n",
       "  secondary2_ind_procentile_90 secondary2_ind_max secondary2_ind_min  \\\n",
       "0                            ?                  ?                  ?   \n",
       "1                            ?                  ?                  ?   \n",
       "2                            ?                  ?                  ?   \n",
       "3                            ?                  ?                  ?   \n",
       "4                            ?                  ?                  ?   \n",
       "\n",
       "  secondary2_ind_sd secondary2_ind_descr      population_time  \n",
       "0                 ?                    ?  06.07.2117 17:50:23  \n",
       "1                 ?                    ?  06.07.2117 17:50:23  \n",
       "2                 ?                    ?  06.07.2117 17:50:23  \n",
       "3                 ?                    ?  06.07.2117 17:50:23  \n",
       "4                 ?                    ?  06.07.2117 17:50:23  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAMETER_NUMBER = '009'\n",
    "CURRENT_DATE = '2018_09_04/'\n",
    "PATH_TO_ROOT_DIRECTORY = 'data/'\n",
    "\n",
    "PATH_TO_DEV_DIRECTORY = PATH_TO_ROOT_DIRECTORY + CURRENT_DATE + 'Dev/'\n",
    "PATH_TO_PUB_DIRECTORY = PATH_TO_ROOT_DIRECTORY + CURRENT_DATE + 'Pub/'\n",
    "PATH_TO_SITE_DIRECTORY = PATH_TO_ROOT_DIRECTORY + CURRENT_DATE + 'Site/'\n",
    "\n",
    "#data = load_dataset(PATH_TO_DEV_DIRECTORY + 'check_'+ PARAMETER_NUMBER +'.txt')\n",
    "data = load_dataset(PATH_TO_DEV_DIRECTORY + PARAMETER_NUMBER + '_check' +'.txt')\n",
    "#data = load_dataset(PATH_TO_DEV_DIRECTORY + 'check_'+ PARAMETER_NUMBER +'_v3.txt')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReportDate</th>\n",
       "      <th>subj</th>\n",
       "      <th>main_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-15</td>\n",
       "      <td>Rossija</td>\n",
       "      <td>6936.2149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-15</td>\n",
       "      <td>Rossija</td>\n",
       "      <td>6343.7634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-03-15</td>\n",
       "      <td>Rossija</td>\n",
       "      <td>7404.6714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>Rossija</td>\n",
       "      <td>6969.3603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-05-15</td>\n",
       "      <td>Rossija</td>\n",
       "      <td>7353.1625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ReportDate     subj   main_ind\n",
       "0 2014-01-15  Rossija  6936.2149\n",
       "1 2014-02-15  Rossija  6343.7634\n",
       "2 2014-03-15  Rossija  7404.6714\n",
       "3 2014-04-15  Rossija  6969.3603\n",
       "4 2014-05-15  Rossija  7353.1625"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_columns = ['ReportDate','subj','cnt_client_tid', 'sum_trans_cnt', 'main_ind','main_ind_sd',\n",
    "                   'main_ind_sum','main_ind_median', 'main_ind_procentile_10', 'main_ind_procentile_90', 'main_ind_max', 'main_ind_min']\n",
    "\n",
    "list_of_columns_short = ['ReportDate','subj', 'main_ind']\n",
    "\n",
    "data = data[list_of_columns_short]\n",
    "#data = data[list_of_columns]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2014-01-15T00:00:00.000000000', '2014-02-15T00:00:00.000000000',\n",
       "       '2014-03-15T00:00:00.000000000', '2014-04-15T00:00:00.000000000',\n",
       "       '2014-05-15T00:00:00.000000000', '2014-06-15T00:00:00.000000000',\n",
       "       '2014-07-15T00:00:00.000000000', '2014-08-15T00:00:00.000000000',\n",
       "       '2014-09-15T00:00:00.000000000', '2014-10-15T00:00:00.000000000',\n",
       "       '2014-11-15T00:00:00.000000000', '2014-12-15T00:00:00.000000000',\n",
       "       '2015-01-15T00:00:00.000000000', '2015-02-15T00:00:00.000000000',\n",
       "       '2015-03-15T00:00:00.000000000', '2015-04-15T00:00:00.000000000',\n",
       "       '2015-05-15T00:00:00.000000000', '2015-06-15T00:00:00.000000000',\n",
       "       '2015-07-15T00:00:00.000000000', '2015-08-15T00:00:00.000000000',\n",
       "       '2015-09-15T00:00:00.000000000', '2015-10-15T00:00:00.000000000',\n",
       "       '2015-11-15T00:00:00.000000000', '2015-12-15T00:00:00.000000000',\n",
       "       '2016-01-15T00:00:00.000000000', '2016-02-15T00:00:00.000000000',\n",
       "       '2016-03-15T00:00:00.000000000', '2016-04-15T00:00:00.000000000',\n",
       "       '2016-05-15T00:00:00.000000000', '2016-06-15T00:00:00.000000000',\n",
       "       '2016-07-15T00:00:00.000000000', '2016-08-15T00:00:00.000000000',\n",
       "       '2016-09-15T00:00:00.000000000', '2016-10-15T00:00:00.000000000',\n",
       "       '2016-11-15T00:00:00.000000000', '2016-12-15T00:00:00.000000000',\n",
       "       '2017-01-15T00:00:00.000000000', '2017-02-15T00:00:00.000000000',\n",
       "       '2017-03-15T00:00:00.000000000', '2017-04-15T00:00:00.000000000',\n",
       "       '2017-05-15T00:00:00.000000000', '2017-06-15T00:00:00.000000000',\n",
       "       '2017-07-15T00:00:00.000000000', '2017-08-15T00:00:00.000000000',\n",
       "       '2017-09-15T00:00:00.000000000', '2017-10-15T00:00:00.000000000',\n",
       "       '2017-11-15T00:00:00.000000000', '2017-12-15T00:00:00.000000000',\n",
       "       '2018-01-15T00:00:00.000000000', '2018-02-15T00:00:00.000000000',\n",
       "       '2018-03-15T00:00:00.000000000', '2018-04-15T00:00:00.000000000',\n",
       "       '2018-05-15T00:00:00.000000000', '2018-06-15T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ReportDate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rossija', 'Altajskij kraj', \"Amurskaja oblast'\",\n",
       "       \"Arhangel'skaja oblast'\", \"Astrahanskaja oblast'\",\n",
       "       \"Belgorodskaja oblast'\", \"Brjanskaja oblast'\",\n",
       "       \"Vladimirskaja oblast'\", \"Volgogradskaja oblast'\",\n",
       "       \"Vologodskaja oblast'\", \"Voronezhskaja oblast'\",\n",
       "       \"Evrejskaja avtonomnaja oblast'\", \"Zabajkal'skij kraj\",\n",
       "       \"Ivanovskaja oblast'\", \"Irkutskaja oblast'\",\n",
       "       'Kabardino-Balkarskaja Respublika', \"Kaliningradskaja oblast'\",\n",
       "       \"Kaluzhskaja oblast'\", 'Kamchatskij kraj', \"Kemerovskaja oblast'\",\n",
       "       \"Kirovskaja oblast'\", \"Kostromskaja oblast'\", 'Krasnodarskij kraj',\n",
       "       'Krasnojarskij kraj', \"Kurganskaja oblast'\", \"Kurskaja oblast'\",\n",
       "       \"Leningradskaja oblast'\", \"Lipetskaja oblast'\",\n",
       "       \"Magadanskaja oblast'\", 'Moskva', \"Moskovskaja oblast'\",\n",
       "       \"Murmanskaja oblast'\", 'Ne opredeleno',\n",
       "       'Nenetskij avtonomnyj okrug', \"Nizhegorodskaja oblast'\",\n",
       "       \"Novgorodskaja oblast'\", \"Novosibirskaja oblast'\",\n",
       "       \"Omskaja oblast'\", \"Orenburgskaja oblast'\", \"Orlovskaja oblast'\",\n",
       "       \"Penzenskaja oblast'\", 'Permskij kraj', 'Primorskij kraj',\n",
       "       \"Pskovskaja oblast'\", 'Respublika Adygeja',\n",
       "       'Respublika Altaj (Gornyj Altaj)', 'Respublika Bashkortostan',\n",
       "       'Respublika Burjatija', 'Respublika Dagestan',\n",
       "       'Respublika Ingushetija', 'Respublika Kalmykija',\n",
       "       'Respublika Karachaevo-Cherkessija', 'Respublika Karelija',\n",
       "       'Respublika Komi', 'Respublika Marij El', 'Respublika Mordovija',\n",
       "       'Respublika Saha (Jakutija)',\n",
       "       'Respublika Severnaja Osetija-Alanija', 'Respublika Tatarstan',\n",
       "       'Respublika Tyva', 'Respublika Hakasija', \"Rostovskaja oblast'\",\n",
       "       \"Rjazanskaja oblast'\", \"Samarskaja oblast'\", 'Sankt-Peterburg',\n",
       "       \"Saratovskaja oblast'\", \"Sahalinskaja oblast'\",\n",
       "       \"Sverdlovskaja oblast'\", \"Smolenskaja oblast'\",\n",
       "       \"Stavropol'skij kraj\", \"Tambovskaja oblast'\", \"Tverskaja oblast'\",\n",
       "       \"Tomskaja oblast'\", \"Tul'skaja oblast'\", \"Tjumenskaja oblast'\",\n",
       "       'Udmurtskaja Respublika', \"Ul'janovskaja oblast'\",\n",
       "       'Habarovskij kraj', 'Hanty-Mansijskij avtonomnyj okrug — Jugra',\n",
       "       \"Cheljabinskaja oblast'\", 'Chechenskaja Respublika',\n",
       "       'Chechenskaja respublika', 'Chuvashskaja Respublika',\n",
       "       'Chukotskij avtonomnyj okrug', 'Jamalo-Nenetskij avtonomnyj okrug',\n",
       "       \"Jaroslavskaja oblast'\"], dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.subj.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество месяцев:  54\n",
      "Количество уникальных регионов:  85\n"
     ]
    }
   ],
   "source": [
    "#количество месяцев и уникальных регионов\n",
    "print('Количество месяцев: ', data.ReportDate.nunique())\n",
    "print('Количество уникальных регионов: ', data.subj.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#приводим даты к середине месяца\n",
    "data.ReportDate = data.ReportDate.map(lambda x: x.replace(day=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check regions-dates\n",
    "\n",
    "Проверка наличия всех дат и регионов в датасете: \n",
    "* Даты сравниваются со списком dates_true из диапазона *START_DATE* : *END_DATE*;\n",
    "* Регионы сравниваются со списком из *subj.txt*, включающим Беларусь, Казахстан, Украину, UNKNOWN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "START_DATE = '2014-01-15'\n",
    "END_DATE = '2018-07-15'\n",
    "\n",
    "#генерируем эталонные даты dates_true для сравнения\n",
    "dates_true = pd.date_range(START_DATE, END_DATE, freq='M')\n",
    "dates_true = dates_true.map(lambda x: x.replace(day=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Проверка присутствия регионов по дате в датасете по списку регионов в subj.txt\n",
    "def check_regions(date, regions_true, regions, wrong_regions):\n",
    "    # Находим разницу множеств реионов и эталонного списка регионов\n",
    "    diff = list(set(regions_true).symmetric_difference(set(regions)))\n",
    "    \n",
    "    # 85 - нормальное число регионов\n",
    "    if set(diff) != set(wrong_regions):\n",
    "        print('WARNING! Date: ', date, 'Wrong Number of regions: ', len(regions))\n",
    "        print('REGIONS missed in dataset: ', diff, '\\n')\n",
    "\n",
    "# Проверка присутствия дат по региону в датасете\n",
    "def check_dates(region, dates_true, dates):\n",
    "    # Находим разницу множеств дат и эталонного списка дат\n",
    "    diff = list(set(dates_true).symmetric_difference(set(dates)))\n",
    "    \n",
    "    if len(diff) != 0:\n",
    "        print('WARNING! Region: ', region,' Number of dates in dateset: ', len(dates))\n",
    "        print('DATES missed in dataset: ', diff, '\\n')\n",
    "\n",
    "# Проверка наличия всех регионов по каждой дате, и всех дат по каждому региону с помощью функций check_regions и check_dates\n",
    "def check_region_date(data):\n",
    "    \n",
    "    df = data[['ReportDate','subj']]\n",
    "    \n",
    "    wrong_regions = [\"Belarus'\", 'Ukraina', 'Kazahstan']\n",
    "    regions_true = pd.read_csv('data/subj.txt', encoding='utf-8', header=0, sep='|')\n",
    "    regions_true = regions_true.rename(columns={regions_true.columns[0]:'subj'})\n",
    "    regions_true.subj = regions_true.subj.map(lambda x: translit(x, reversed=True) if x != 'UNKNOWN'  else x)\n",
    "    \n",
    "    # Для каждой даты в данных проверяем наличие всех регионов\n",
    "    for date in df.ReportDate.unique():\n",
    "        check_regions(date, regions_true.subj.values, df[df.ReportDate == date].subj.values, wrong_regions)\n",
    "    # Для каждого региона в данных проверяем наличие всех дат\n",
    "    for region in df.subj.unique():\n",
    "        check_dates(region, dates_true, df[df.subj == region].ReportDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Печатает предупреждения в случае пропусков регионов или дат\n",
    "check_region_date(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сверка текущих данных с выложенными ранее (с предыдущей папкой site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data_from_js(file_path):\n",
    "    '''\n",
    "    Метод считывает построчно .js файл, записывает все в большую строку flat_string, затем сохраняет в датафрейм\n",
    "    param:\n",
    "        file_path: Путь к файлу\n",
    "    return:\n",
    "        data: DataFrame с данными\n",
    "    '''\n",
    "    with open(file_path, 'r') as js_file:\n",
    "        FIRST_LINE = True\n",
    "        flat_string = ''\n",
    "        # считываем построчно .js файл\n",
    "        for line in js_file:\n",
    "            \n",
    "            flat_string += line\n",
    "            break\n",
    "            '''if ']' in line:\n",
    "                break\n",
    "            \n",
    "            if FIRST_LINE == True:\n",
    "                FIRST_LINE = False\n",
    "                #добавляем скобку для корректного считывания json файла\n",
    "                flat_string = flat_string + '['\n",
    "            else:\n",
    "                flat_string = flat_string + line\n",
    "        #добавляем скобку для корректного считывания json файла \n",
    "        flat_string = flat_string + ']'''\n",
    "        #flat_string = flat_string[8:-2]\n",
    "    #print flat_string\n",
    "    # Конвертим json в датафрейм\n",
    "    result = pd.read_json(flat_string, convert_dates = False)\n",
    "    # конвертим дату из unix timestamp в pandas timestamp\n",
    "    result.date = pd.to_datetime(result.date, unit = 'ms').map(lambda x: x.replace(day=15, hour=0))\n",
    "    # транслит названий регионов для сравнения\n",
    "    result.region = result.region.map(lambda x: translit(x, reversed=True) if x != 'UNKNOWN'  else x)\n",
    "    result.value = result.value.astype('float')\n",
    "    # Переименовываем колонки к формату файла \"_check.txt\"\n",
    "    new_column_names = ['ReportDate', 'subj', 'main_ind']\n",
    "    result.rename(columns = dict(zip(result.columns,  new_column_names)), inplace = True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def compare_data_with_old_js(data, old_data):\n",
    "    '''\n",
    "    Метод мерджит 2 таблицы и вычисляет разницу в значениях main_ind - main_ind_old, в т.ч. в %\n",
    "    param:\n",
    "        data: Датафрейм с новыми данными, всего 3 колонки: ReportDate, subj, main_ind\n",
    "        old_data: Датафрейм со старыми данными, всего 3 колонки: ReportDate, subj, main_ind\n",
    "    return:\n",
    "        data_merge: Датафрейм с разницой значений в абсолюте и в %\n",
    "    '''\n",
    "    data_merge = old_data.merge(data, how='left', on=['subj','ReportDate'], sort=False, suffixes = ['_old',''])\n",
    "    data_merge['main_ind_diff'] = data_merge.main_ind - data_merge.main_ind_old\n",
    "    data_merge['main_ind_diff_percent'] = (data_merge.main_ind - data_merge.main_ind_old)/data_merge.main_ind_old\n",
    "\n",
    "    return data_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReportDate</th>\n",
       "      <th>subj</th>\n",
       "      <th>main_ind_old</th>\n",
       "      <th>main_ind</th>\n",
       "      <th>main_ind_diff</th>\n",
       "      <th>main_ind_diff_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ReportDate, subj, main_ind_old, main_ind, main_ind_diff, main_ind_diff_percent]\n",
       "Index: []"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TO_SITE_PREVIOUS = PATH_TO_SITE_DIRECTORY + 'Site_previous/'\n",
    "PATH_TO_JS_FILE = PATH_TO_SITE_PREVIOUS + 'data'+ PARAMETER_NUMBER + '.js'\n",
    "\n",
    "# считываем данные из .js в датафрейм\n",
    "old_data = read_data_from_js(PATH_TO_JS_FILE)\n",
    "# сравниваем датафреймы\n",
    "data_compare = compare_data_with_old_js(data[['ReportDate','subj','main_ind']], old_data)\n",
    "data_compare[np.abs(data_compare.main_ind_diff_percent) > 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReportDate</th>\n",
       "      <th>subj</th>\n",
       "      <th>main_ind_old</th>\n",
       "      <th>main_ind</th>\n",
       "      <th>main_ind_diff</th>\n",
       "      <th>main_ind_diff_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ReportDate, subj, main_ind_old, main_ind, main_ind_diff, main_ind_diff_percent]\n",
       "Index: []"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_compare[(np.abs(data_compare.main_ind_diff_percent) > 0.02)&(data_compare.ReportDate != '2018-05-15')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Медианное отклонение от медианы регионов\n",
    "\n",
    "Находим отклонение региона по каждой дате от медианы всех остальных регионов, т.е. отклонение от общих, групповых трендов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#приводим даты к концу месяца\n",
    "data.ReportDate = data.ReportDate.apply(lambda x: x + MonthEnd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def median_absolute_deviation(data):\n",
    "    \"\"\"\n",
    "    Метод вычисляет медианное отклонение от медианы (MAD) для данных\n",
    "    \"\"\"\n",
    "    const = 0.6745 #0.75 percentile of normal distribution\n",
    "    if data.ndim > 1 :\n",
    "        MAD_ = np.median(np.abs(data - np.median(data, -1).reshape(data.shape[0], -1)), -1)/const\n",
    "\n",
    "    if data.ndim == 1:\n",
    "        MAD_ = np.median(np.abs(data - np.median(data)))/const\n",
    "    \n",
    "    # single dimention data\n",
    "    #median_ = np.median(data, axis=0)\n",
    "    #MAD_ = np.median((np.abs(data - median_)))/const\n",
    "    \n",
    "    return MAD_\n",
    "\n",
    "#####################################################\n",
    "def mad_region_group(data, threshold = 3.):\n",
    "    \"\"\"\n",
    "    В проверке находится медиана регионов по каждой дате и\n",
    "    отклонение от этой медианы по каждой дате.\n",
    "    \n",
    "    params:\n",
    "        threshold: порог по которому проставляется флаг выброса, по умолчанию 3\n",
    "    \"\"\"\n",
    "    # Находим медиану по регионам, выбрасываем Россию и неизвестные при рассчетах\n",
    "    data_all = data[~data.subj.isin(['Rossija','UNKNOWN','Ne opredeleno'])]\\\n",
    "        .groupby(['ReportDate'], as_index=False)\\\n",
    "        .agg({'main_ind':'median'})\\\n",
    "        .rename(columns={'main_ind':'main_ind_median'})\n",
    "    \n",
    "    # Собираем плоскую таблицу в таблицу по датам (регионы - столбцы, даты - строки)\n",
    "    for subj_ in data[~data.subj.isin(['UNKNOWN','Rossija', 'Ne opredeleno'])].subj.unique():\n",
    "        #print(subj_)\n",
    "        temp = data[data.subj == subj_][['ReportDate', 'main_ind']].rename(columns={'main_ind':'main_ind'+'_'+subj_}).copy()\n",
    "        data_all = data_all.merge(temp, how='left', on=['ReportDate'])\n",
    "    \n",
    "    # Заполним пропуски в данных нулями\n",
    "    data_all = data_all.fillna(0.)\n",
    "    \n",
    "    # Мастштабируем (стандартизируем) каждый регион в отдельности\n",
    "    columns_to_scale = [col for col in data_all.columns if 'main_ind' in col]\n",
    "    data_all_scaled = pd.DataFrame(StandardScaler().fit_transform(data_all[columns_to_scale]), columns=columns_to_scale)\n",
    "    data_all_scaled['ReportDate'] = data_all['ReportDate'].copy()\n",
    "    \n",
    "    \n",
    "    # Применяем MAD регионов по датам\n",
    "    # Найдем медиану отмасштабированных рядов \n",
    "    columns_to_med =[col for col in data_all_scaled.columns if 'main_ind' in col \n",
    "                      and 'main_ind_median' not in col\n",
    "                      and 'main_ind_Rossija' not in col]\n",
    "    data_all_scaled['main_ind_median_scaled'] = data_all_scaled[columns_to_med].apply(np.median, axis=1)\n",
    "    \n",
    "    # Вычитаем из каждого региона медиану \n",
    "    columns_to_subtract = [col for col in data_all_scaled.columns if 'main_ind' in col \n",
    "                       and 'main_ind_median' not in col\n",
    "                       and 'main_ind_median_scaled' not in col]\n",
    "    for col in columns_to_subtract:\n",
    "        data_all_scaled[col] = data_all_scaled[col] - data_all_scaled['main_ind_median_scaled']\n",
    "    \n",
    "    # Находим MAD и медиану отклонения\n",
    "    data_all_scaled['MAD'] = data_all_scaled[columns_to_subtract].apply(lambda x: median_absolute_deviation(x), axis=1)\n",
    "    data_all_scaled['diff_median'] = data_all_scaled[columns_to_subtract].apply(lambda x: np.median(x), axis=1)\n",
    "    \n",
    "    # Рассчитываем метки для точек: больше 3 медианных отклонений - выброс\n",
    "    for col in columns_to_subtract:\n",
    "        data_all_scaled[col + '_label'] = (np.abs(data_all_scaled[col] - data_all_scaled['diff_median']) > threshold * data_all_scaled['MAD']).astype(int)\n",
    "        \n",
    "    return data_all, data_all_scaled\n",
    "\n",
    "#####################################################\n",
    "\n",
    "def print_mad_region_group(data_all, data_all_scaled, parameter_number = PARAMETER_NUMBER):\n",
    "    \"\"\"\n",
    "    Метод выводит в файл графики по регионам где есть отклонения\n",
    "    \"\"\"\n",
    "    # Задаем название файла\n",
    "    report_name = pd.to_datetime('now').strftime(\"%Y_%m_%d_%H_%M\")\n",
    "    pp = PdfPages('mad_region_' + parameter_number + '_' + report_name + '.pdf')\n",
    "    # Поля для использования\n",
    "    columns_to_use = [col for col in data_all_scaled.columns if 'main_ind' in col \n",
    "                     and 'main_ind_median' not in col\n",
    "                     and 'main_ind_median_scaled' not in col\n",
    "                     and '_label' not in col]\n",
    "    \n",
    "    for col in columns_to_use:\n",
    "        # Находим метки выбросов\n",
    "        list_of_inds = data_all_scaled[data_all_scaled[col + '_label'] == 1].index\n",
    "        if len(list_of_inds >0):\n",
    "            # Создаем график по каждому региону с выбросом\n",
    "            fig, ax = plt.subplots(figsize=(20,8))\n",
    "            #plt.clf()\n",
    "            data_all.plot(kind='line', x='ReportDate', y=[col,'main_ind_median'], ax=ax, title=col)\n",
    "            # Помечаем точки как выбросы\n",
    "            for ind in list_of_inds:\n",
    "                plt.annotate('outlier', xy=([data_all.ReportDate.iloc[ind],data_all[col].iloc[ind]]), xycoords='data',xytext=(+20, +20), textcoords='offset points', fontsize=14,\n",
    "                             arrowprops = dict(arrowstyle=\"-|>\", connectionstyle=\"arc3, rad=0.\", color='green'), color='green')\n",
    "            pp.savefig()\n",
    "    pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.46 s, sys: 8.76 ms, total: 1.47 s\n",
      "Wall time: 2.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_all, data_all_scaled = mad_region_group(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mad_region_group(data_all, data_all_scaled, parameter_number = PARAMETER_NUMBER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ансамблирование Window MAD отдельно по каждому региону"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def rolling_window(data, window):\n",
    "    '''\n",
    "    One of the fastest way for doing rolling windows over numpy array.\n",
    "    '''\n",
    "    shape = data.shape[:-1] + (data.shape[-1] - window + 1, window)\n",
    "    strides = data.strides + (data.strides[-1],)\n",
    "    \n",
    "    return np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)\n",
    "\n",
    "############################################\n",
    "\n",
    "def calculate_window_mad(data, window_size = 3, threshold = 3.):\n",
    "    '''\n",
    "    Метод вычисляет для каждой точки из ряда data (кроме первых window_size точек)\n",
    "    выброс она или нет по предыдущим window_size точкам\n",
    "    params:\n",
    "        data: numpy array, float, ряд \n",
    "        window_size: int, размер окна\n",
    "        threshold: float, порог отсечения для метки выброс/нет\n",
    "    return:\n",
    "        labels_: list, int, массив меток выброс/нет\n",
    "    '''\n",
    "    labels_ = [0]*window_size\n",
    "    # Состовляем скользящие окна для каждой точки из предыдущих точек \n",
    "    window_data = rolling_window(data, window_size)[:-1]\n",
    "    # Рассчитываем медиану и MAD для каждого окна\n",
    "    window_median = np.median(window_data, axis=1)\n",
    "    window_mad = median_absolute_deviation(window_data)\n",
    "    \n",
    "    # Рассчитываем метки выброс/нет по ранее рассчитаным медианам и отклонениям\n",
    "    labels_.extend((np.abs(data[window_size:] - window_median) > threshold * window_mad).astype(int))\n",
    "    \n",
    "    return labels_\n",
    "\n",
    "############################################\n",
    "\n",
    "def ensemble_window_mad(data, ensemble_threshold = 0.7, params = {'threshold': [2.5, 3., 3.5], 'window_size': [5, 7, 9]}):\n",
    "    '''\n",
    "    Метод ансамблирует несклько вычислений calculate_window_mad\n",
    "    params:\n",
    "        data: numpy array, float, ряд \n",
    "        ensemble_threshold: int, порог для выставлении метки при ансамблировании\n",
    "        params: dict, зачения для threshold, window_size\n",
    "    return:\n",
    "        result_labels: list, метки после ансамблирования\n",
    "    '''\n",
    "    ensemble_labels = []\n",
    "    # Для каждого значения параметров рассчитаем window MAD\n",
    "    for threshold, window_size in product(params['threshold'], params['window_size']):\n",
    "        labels = calculate_window_mad(data, window_size, threshold)\n",
    "        ensemble_labels.append(labels)\n",
    "    # Получаем по каждой точке среднее значение меток, \n",
    "    # выставляем итоговую метку по порогу ансамблирования\n",
    "    result_labels_ = np.mean(ensemble_labels, axis = 0)\n",
    "    result_labels = list(map(lambda x: 0 if x < ensemble_threshold else 1, result_labels_))\n",
    "    \n",
    "    return result_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_ensemble_window_mad_data(data, **args):\n",
    "    '''\n",
    "    Метод вычисляет для каждого регионального ряда метки через ансамблирование window_mad\n",
    "    params:\n",
    "        data: numpy array, float, ряд\n",
    "        args: аргументы для ensemble_window_mad:\n",
    "                ensemble_threshold: int, порог для выставлении метки при ансамблировании, \n",
    "                params: dict, зачения для threshold, window_size\n",
    "    return:\n",
    "        data_all: pandas dataframe, региональные ряды по столбцам + столбцы с метками\n",
    "    '''\n",
    "    \n",
    "    # Находим медиану по регионам, выбрасываем Россию и неизвестные при рассчетах\n",
    "    data_all = data[~data.subj.isin(['Rossija','UNKNOWN','Ne opredeleno'])]\\\n",
    "        .groupby(['ReportDate'], as_index=False)\\\n",
    "        .agg({'main_ind':'median'})\\\n",
    "        .rename(columns={'main_ind':'main_ind_median'})\n",
    "    \n",
    "    # Собираем плоскую таблицу в таблицу по датам (регионы - столбцы, даты - строки)\n",
    "    for subj_ in data[~data.subj.isin(['UNKNOWN','Ne opredeleno'])].subj.unique():\n",
    "        temp = data[data.subj == subj_][['ReportDate', 'main_ind']].rename(columns={'main_ind':'main_ind'+'_'+subj_}).copy()\n",
    "        data_all = data_all.merge(temp, how='left', on=['ReportDate'])\n",
    "\n",
    "    # для каждого регионального ряда вычисляем метки ансамбля\n",
    "    col_to_use = [col for col in data_all.columns if 'main_ind' in col and 'main_ind_median' not in col]\n",
    "    for col in col_to_use:\n",
    "        data_all[col + '_label'] = ensemble_window_mad(data_all[col].values, **args)\n",
    "    \n",
    "    return data_all\n",
    "\n",
    "############################################\n",
    "\n",
    "def print_ensemble_window_mad(data_all, parameter_number = PARAMETER_NUMBER):\n",
    "    \"\"\"\n",
    "    Метод выводит в файл графики по регионам где есть отклонения\n",
    "    \"\"\"\n",
    "    # Задаем название файла\n",
    "    report_name = pd.to_datetime('now').strftime(\"%Y_%m_%d_%H_%M\")\n",
    "    pp = PdfPages('ensemble_window_mad_' + parameter_number + '_' + report_name + '.pdf')\n",
    "    # Поля для использования\n",
    "    columns_to_use = [col for col in data_all.columns if 'main_ind' in col \n",
    "                     and 'main_ind_median' not in col\n",
    "                     and '_label' not in col]\n",
    "    \n",
    "    for col in columns_to_use:\n",
    "        # Находим метки выбросов\n",
    "        list_of_inds = data_all[data_all[col + '_label'] == 1].index\n",
    "        if len(list_of_inds >0):\n",
    "            # Создаем график по каждому региону с выбросом\n",
    "            fig, ax = plt.subplots(figsize=(20,8))\n",
    "            data_all.plot(kind='line', x='ReportDate', y=[col,'main_ind_median'], ax=ax, title=col)\n",
    "            # Помечаем точки как выбросы\n",
    "            for ind in list_of_inds:\n",
    "                plt.annotate('outlier', xy=([data_all.ReportDate.iloc[ind], data_all[col].iloc[ind]]), xycoords='data',xytext=(+20, +20), textcoords='offset points', fontsize=14,\n",
    "                             arrowprops = dict(arrowstyle=\"-|>\", connectionstyle=\"arc3, rad=0.\", color='green'), color='green')\n",
    "            pp.savefig()\n",
    "    pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.81 s, sys: 3.95 ms, total: 1.82 s\n",
      "Wall time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_all_2 = calculate_ensemble_window_mad_data(data, ensemble_threshold = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_ensemble_window_mad(data_all_2, parameter_number = PARAMETER_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.3 (ZNO20008661)",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
